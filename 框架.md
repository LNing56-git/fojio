> 抱佛脚一时爽，一直抱佛脚一直爽！这篇文章总结常见的框架面试问题~因为是抱佛脚，所以结构上没有什么逻辑...
>
> 参考链接：[Waking-Up](https://github.com/wolverinn/Waking-Up)  [CycNotes](https://github.com/CyC2018/CS-Notes)  [牛客网](https://www.nowcoder.com/) 



# faiss

### 使用场景

返回相似的高维向量，faiss本质上就是一个存储高维向量的数据库

### 搜索方法

- PQ
  - 指定M，将每个N维向量切为M段
  - 把所有向量的第一段取出来做Clustering得到256个簇心，再把所有向量的第二段取出来做Clustering得到256个簇心，直至对所有向量的第N段做完Clustering，从而最终得到了256*M个簇心
  - 把原来的N维的向量映射到M个数字：以N=128，M=4为例，首先把向量切成四段，然后对于每一段向量，都可以找到对应的最近的簇心 ID，4段向量就对应了4个簇心 ID，一个128维的向量就变成了一个由4个ID组成的向量
  - 对于每一个查询向量，以相同的方法把128维分成4段32维向量
  - 计算查询向量的每一段与之前预训练好的簇心的距离，得到一个4*256的表
  - 计算查询向量与数据库中每个向量的距离：比如的库里的某个向量被量化成了[124, 56, 132, 222]，那么首先查表得到查询向量第一段子向量与其ID为124的簇心的距离，然后再查表得到查询向量第二段子向量与其ID为56的簇心的距离...最后就可以得到四个距离d1、d2、d3、d4，查询向量跟库里向量的距离d = d1+d2+d3+d4
- IFS
  - 对库里所有向量做KMeans Clustering，假设簇心个数为1024
  - 每来一个查询向量，首先计算其与1024个粗聚类簇心的距离
  - 然后选择距离最近的top N个簇，只计算查询向量与这几个簇底下的向量的距离，计算距离的方法就是前面说的PQ

# rpc

### 含义

- 本地过程调用：传递入参、调用函数执行业务逻辑、返回出参都是在同一进程空间进行的
- RPC就是从一台机器（客户端）上通过参数传递的方式调用另一台机器（服务器）上的一个函数或方法（可以统称为服务）并得到返回的结果

- 调用远程的过程就像调用本地的子程序一样
- RPC本质上是一种 Inter-process communication（IPC）——进程间通信的形式

### 开发步骤

- 定义一个接口说明文件：描述了对象(结构体)、对象成员、接口方法等一系列信息
- 通过RPC框架所提供的编译器，将接口说明文件编译成具体的语言文件
- 在客户端和服务器端分别引入RPC编译器所生成的文件，即可像调用本地方法一样调用服务端代码

### 调用步骤

- 用户通过函数调用把参数传给client stub，参数像普通函数一样存在栈内
- client stub把参数打包为一个消息，通过系统调用来传消息
- 客户端的os把消息传给服务端
- 服务端的os把消息传给server stub
- server stub把参数从消息中拆出来，并以它们为形参调用服务端的函数

# thrift

- 分层：从上到下
  - 用户自行实现的业务逻辑代码
  - Processor：处理客户端请求或者接收服务端响应
    - 向Message结构中读出请求数据
    - 调用参数解析和用户逻辑
    - 向Message结构中写入返回数据
  - TServer：负责接收Client的请求，并将请求转发到Processor进行处理
  - TProtocol：用来对数据进行序列化与反序列化，具体方法包括二进制，JSON等
    - 将结构化数据转化为字节流给TTransport进行传输
    - 从TTransport中读取一定长度的字节数据转化为特定类型的数据
  - TTransport：负责以字节流方式发送和接收Message
    - 每一个底层IO模块都会有一个对应TTransport来负责Thrift的字节流数据在该IO模块上的传输
  - 底层IO：负责实际的数据传输，包括socket、文件和压缩数据流等
- 流程
  - 将客户端程序调用的函数名和参数传递给协议层（TProtocol），协议层将函数名和参数按照协议格式（如json、二进制等）进行封装，然后封装的结果交给下层的传输层
  - 客户端传输层（TTransport）将协议层传递过来的数据转换为字节流，例如传输层的TFramedTransport就是将数据封装成帧的形式，即“数据长度+数据内容”，然后将处理之后的数据通过网络（可使用tcp等协议）发送给服务端
  - 服务端传输层（TTransport）接收网络上传输过来的调用请求数据，将接收到的数据进行逆向的处理，例如传输层的TFramedTransport就是将“数据长度+数据内容”形式的网络数据，转成只有数据内容的形式，然后再交付给服务端的协议类（TProtocol）
  - 服务端的协议类（TProtocol）将传输层处理之后的数据按照协议（如json、二进制等）解封装为结构化数据，交给Processor类进行处理
  - 服务端Processor：
    *TProcessor.process首先调用TTransport.readMessageBegin接口，读出RPC调用的名称和RPC调用类型。如果RPC调用类型是RPC Call，则调用TProcessor.process_fn继续处理，对于未知的RPC调用类型，则抛出异常
    *TProcessor.process_fn根据RPC调用名称到自己的processMap【Key为RPC名称。Value是对应的RPC处理函数的函数指针】中查找对应的RPC处理函数。如果存在对应的RPC处理函数，则调用该处理函数继续进行请求响应。不存在则抛出异常
    *RPC处理函数
    	~调用RPC请求参数的解析类，从TProtocol中读入数据完成参数解析【不管RPC调用的参数有多少个，Thrift都会将参数放到一个Struct中去。Thrift会检查读出参数的字段ID和字段类型是否与要求的参数匹配。对于不符合要求的参数都会跳过。这样，RPC接口发生变化之后，旧的处理函数在不做修改的情况，可以通过跳过不认识的参数，来继续提供服务】
    	~参数解析完成之后，调用用户逻辑，完成真正的请求响应
    	~用户逻辑的返回值使用返回值打包类进行打包，写入TProtocol
  - 服务端的协议类（TProtocol）将函数的执行结果进行封装为结构化数据
  - 服务端的传输层将协议层封装的结果进行处理，例如封装成帧，然后发送给Thrift客户端程序
  - 客户端的传输层将收到的网络结果进行逆向处理，得到实际的协议数据
  - 客户端的协议层将数据按照协议格式进行解封装，然后得到具体的函数执行结果，并将其交付给调用函数
- 优点
  - thrift通过一个中间语言IDL(接口定义语言)来定义RPC的数据类型和接口,这些内容写在以.thrift结尾的文件中,然后通过特殊的编译器来生成不同语言的代码,以满足不同需要的开发者
  - 已经支持很多协议，很多传输通道，不需要自己再封装协议并搭建、配置服务器,可以大大减少开发时间
  - 数据结构与传输表现的分离，支持多种消息格式
- 缺点
  - Thrift适用于程序对程序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程【这一点和protobuf一样】

# zookeeper

### 功能

- master选举：可以让所有服务节点去竞争性地创建同一个 ZNode，由于 Zookeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为 Master 节点
- 分布式锁：所有服务节点可以竞争性地去创建同一个临时 ZNode，由于 Zookeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，此时可以认为该节点获得了锁
- 集群管理
  - 如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发
  - 每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报
  - 通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容
    - 客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端
    - 栗子：假设我们的程序是分布式部署在多台机器上，如果我们要改变程序的配置文件，需要逐台机器去修改，非常麻烦，现在把这些配置全部放到zookeeper上去，保存在 zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 zookeeper 的通知，然后从 zookeeper 获取新的配置信息应用到系统中
  - 负载均衡
  - 存放元数据：partition的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他“人”都要与它 保持对齐

### 节点分类

- 永久节点：不会因为会话结束或者超时而消失；
- 临时节点：如果会话结束或者超时就会消失；
- 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推

### zookeeper与kafka

- 发布者将数据发布到ZooKeeper的一个或一系列节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中管理和数据的动态更新
- kafaka集群的 broker 和 Consumer 都需要连接 Zookeeper，Producer 直接连接 Broker
- 每个Broker在启动时都会到/brokers/ids下创建属于自己的节点（IP地址+端口）；Broker创建的节点类型是临时节点，一旦Broker宕机，则对应的临时节点也会被自动删除
- 同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护；Kafka中每个Topic都会以/brokers/topics/[topic]的形式被记录
- 生产者负载均衡：让生产者将消息合理地发送到这些分布式的Broker上
- 消费者负载均衡：每个partition 只能被同组的一个消费者进行消费，所以需要实现消息合理分配到同组的多个消费者上

### zookeeper与服务

- 服务端向ZooKeeper集群注册自己提供的服务，并且把自己的IP地址和服务端口创建到具体的服务目录下
- 客户端向ZooKeeper集群监听自己关注的RPC服务，监听服务目录下的IP地址列表变化，RPC的客户端根据监听到的多个IP服务提供者，根据每个IP的负载情况，动态选择最优可用的RPC服务端并且调用服务【负载均衡的实现：在配置中配权重/随机】
- 服务目录是持久节点（一旦这个节点被创建了，除非主动进行删除操作，否则这个节点将一直保存在ZooKeeper中）
- 每次客户端与服务端建立连接都会在对应服务目录下新增一个临时节点，一旦客户端会话失效则移除该临时节点，这个移除是通过心跳检测实现的：它会定时向各个服务提供者发送一个请求，如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除

# kafka

### 组成

- producer：往topic里push data
- consumer：主动到指定的topic里读data；consumer 消费消息时，向 broker 发出"fetch"请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新消费之前的消息
- topic：会分为多个partition，各partition可能存在不同broker中，同一个topic的同一个partition可能有复制品（取决于复制因子，建议与Broker节点数量一致）
- partition：若一个partition有多个复制品，它们中会有一个是leader，其他是follower；leader处理该Partition分区的所有读和写请求；follower被动地复制leader做出的改变；如果该Partition分片的领导者发生了故障等，follower中会有一个成为leader
- broker：负责把数据存储到内存并持久化到磁盘

### 文件存储

- offset是指要取的message在该partition中的偏移量，可以理解为message id
- 假设将数据文件分成5段，第一段为0-19，第二段为20-39，以此类推，每段放在一个单独的数据文件里面，数据文件以该段中最小的offset命名。这样在查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个段中
- 每个段文件有一个索引文件，用于在段文件中查找offset对应的message
- 每条索引包含两个字段：相对offset（因为数据文件分段以后，每个数据文件的起始offset不为0，相对offset表示这条Message相对于其所属数据文件中最小的offset的大小）、position（表示该条Message在数据文件中的绝对位置。只要打开文件并移动文件指针到这个position就可以读取对应的Message了），所以要找message的position只需要通过二分搜索即可
- index文件中并没有为数据文件中的每条Message建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。但缺点是没有建立索引的Message也不能一次定位到其在数据文件的位置，从而需要做一次顺序扫描，但是这次顺序扫描的范围就很小

### ack机制

request.required.acks 有三个值 0 1 -1
 - 0：生产者不等broker的ack
- 1：生产者会等待leader 确认接收到消息后发送的 ack
- -1：生产者会等所有的 follower 的副本受到数据后leader 发出的 ack

### 消费者组

- 由一个或多个共同消费一组订阅主题的消费者组成
- 对于每个消费者组 (Consumer Group)，Kafka都会为其分配一个全局唯一的Group ID，Group 内部的所有消费者共享该 ID。每个partition 只能被同组的一个消费者进行消费

# git

### merge vs rebase

- merge

  自动根据两个分支的共同祖先和两个分支的最新提交进行三方合并，然后将合并中修改的内容生成一个新commit，原来分支的commit记录仍然会保存

- rebase

  从两个分支的共同祖先提取当前分支上的修改，将当前分支上所有修改合并到目标分支的最新提交后面，所以rebase后只剩下一个分支的commit记录

### 分区

暂存区：git add之后commit之前存在的区域；

工作区：git commit之后存在的区域；

远程仓库：git push之后

# restful api

- 对网络上的所有资源，都有一个统一资源标识符 URI(Uniform Resource Identifier)
- 这些资源可以有多种表现形式，即REST中的“表现层”Representation，比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现。URI只代表资源的实体，不代表它的形式
- “无状态(Stateless)”思想：服务端不应该保存客户端状态，只需要处理当前的请求，不需了解请求的历史，客户端每一次请求中包含处理该请求所需的一切信息
- 客户端使用HTTP协议中的 GET/POST/PUT/DELETE 方法对服务器的资源进行操作，即REST中的”状态转化“